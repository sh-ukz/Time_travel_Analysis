{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all sheets from the Excel file\n",
    "file_path = \"copy_whole_forward.xlsx\"  # Change if needed\n",
    "xls = pd.read_excel(file_path, sheet_name=None)  # Load all sheets as dict\n",
    "\n",
    "# Function to clean each sheet\n",
    "def clean_sheet(df):\n",
    "    # 1. Remove rows with missing START or END\n",
    "    df = df.dropna(subset=[\"START\", \"END\"])\n",
    "\n",
    "    # 2. Convert DISTANCE to meters\n",
    "    def convert_distance(dist):\n",
    "        if isinstance(dist, str):\n",
    "            dist = dist.strip()\n",
    "            if \"km\" in dist:\n",
    "                return float(dist.replace(\" km\", \"\").strip()) * 1000\n",
    "            elif \"m\" in dist:\n",
    "                return float(dist.replace(\" m\", \"\").strip())\n",
    "        return np.nan\n",
    "\n",
    "    df[\"DISTANCE_M\"] = df[\"DISTANCE\"].apply(convert_distance)\n",
    "\n",
    "    # 3. Convert durations to seconds\n",
    "    def convert_duration(duration):\n",
    "        if isinstance(duration, str):\n",
    "            duration = duration.strip().lower()\n",
    "            if \"hour\" in duration:\n",
    "                parts = duration.replace(\"hours\", \"\").replace(\"hour\", \"\").replace(\"mins\", \"\").replace(\"min\", \"\").split()\n",
    "                if len(parts) == 2:\n",
    "                    return int(parts[0]) * 3600 + int(parts[1]) * 60\n",
    "                elif len(parts) == 1:\n",
    "                    return int(parts[0]) * 3600\n",
    "            elif \"min\" in duration:\n",
    "                return int(duration.replace(\"mins\", \"\").replace(\"min\", \"\").strip()) * 60\n",
    "            elif \"sec\" in duration:\n",
    "                return int(duration.replace(\"secs\", \"\").replace(\"sec\", \"\").strip())\n",
    "        return np.nan\n",
    "\n",
    "    df[\"DURATION_SEC\"] = df[\"DURATION\"].apply(convert_duration)\n",
    "    df[\"DURATION_IN_TRAFFIC_SEC\"] = df[\"DURATION_IN_TRAFFIC\"].apply(convert_duration)\n",
    "\n",
    "    # 4. Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # 5. Create time-based columns\n",
    "    df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "    df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "    df[\"WEEKDAY\"] = df[\"DATE&TIME\"].dt.day_name()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean all sheets\n",
    "cleaned_sheets = {sheet_name: clean_sheet(df.copy()) for sheet_name, df in xls.items()}\n",
    "\n",
    "# Save the cleaned data back to a new Excel file\n",
    "output_path = \"cleaned_all_sheets_forward.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, df in cleaned_sheets.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"✅ All sheets cleaned and saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6000c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"copy_whole_forward.xlsx\"  # Replace with your path\n",
    "xls = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "missing_start_end = []\n",
    "\n",
    "for sheet_name, df in xls.items():\n",
    "    if not {\"START\", \"END\"}.issubset(df.columns):\n",
    "        missing_start_end.append(sheet_name)\n",
    "\n",
    "print(\"Sheets missing 'START' and 'END':\")\n",
    "print(missing_start_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6dee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"copy_whole_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "cleaned_sheets = {}\n",
    "\n",
    "# Conversion helpers\n",
    "def convert_distance(dist):\n",
    "    if isinstance(dist, str):\n",
    "        if \"km\" in dist:\n",
    "            num = float(dist.replace(\"km\", \"\").strip())\n",
    "            return int(num * 1000)\n",
    "        elif \"m\" in dist:\n",
    "            return int(dist.replace(\"m\", \"\").strip())\n",
    "    return pd.NA\n",
    "\n",
    "def convert_duration(dur):\n",
    "    if isinstance(dur, str):\n",
    "        minutes = re.findall(r\"(\\d+)\\s*min\", dur)\n",
    "        seconds = re.findall(r\"(\\d+)\\s*sec\", dur)\n",
    "        total = 0\n",
    "        if minutes:\n",
    "            total += int(minutes[0]) * 60\n",
    "        if seconds:\n",
    "            total += int(seconds[0])\n",
    "        return total\n",
    "    return pd.NA\n",
    "\n",
    "# Clean each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "    \n",
    "    # Detect correct header row\n",
    "    header_row = None\n",
    "    for i in range(10):\n",
    "        row = df_raw.iloc[i]\n",
    "        if \"START\" in row.values and \"END\" in row.values:\n",
    "            header_row = i\n",
    "            break\n",
    "\n",
    "    if header_row is None:\n",
    "        print(f\"Skipping {sheet_name}: No header with START and END found.\")\n",
    "        continue\n",
    "\n",
    "    # Load sheet with proper header\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row)\n",
    "    \n",
    "    # Drop rows with missing START or END\n",
    "    df = df.dropna(subset=[\"START\", \"END\"]).copy()\n",
    "\n",
    "    # Convert distance and duration fields\n",
    "    df[\"DISTANCE_M\"] = df[\"DISTANCE\"].apply(convert_distance)\n",
    "    df[\"DURATION_SEC\"] = df[\"DURATION\"].apply(convert_duration)\n",
    "    df[\"DURATION_IN_TRAFFIC_SEC\"] = df[\"DURATION_IN_TRAFFIC\"].apply(convert_duration)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Add time-based columns (if TIME column exists)\n",
    "    if \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"copy_whole_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "cleaned_sheets = {}\n",
    "\n",
    "# Conversion helpers\n",
    "def convert_distance(dist):\n",
    "    if isinstance(dist, str):\n",
    "        if \"km\" in dist:\n",
    "            num = float(dist.replace(\"km\", \"\").strip())\n",
    "            return int(num * 1000)\n",
    "        elif \"m\" in dist:\n",
    "            return int(dist.replace(\"m\", \"\").strip())\n",
    "    return pd.NA\n",
    "\n",
    "def convert_duration(dur):\n",
    "    if isinstance(dur, str):\n",
    "        minutes = re.findall(r\"(\\d+)\\s*min\", dur)\n",
    "        seconds = re.findall(r\"(\\d+)\\s*sec\", dur)\n",
    "        total = 0\n",
    "        if minutes:\n",
    "            total += int(minutes[0]) * 60\n",
    "        if seconds:\n",
    "            total += int(seconds[0])\n",
    "        return total\n",
    "    return pd.NA\n",
    "\n",
    "# Clean each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "    \n",
    "    # Detect correct header row\n",
    "    header_row = None\n",
    "    for i in range(10):\n",
    "        row = df_raw.iloc[i]\n",
    "        if \"START\" in row.values and \"END\" in row.values:\n",
    "            header_row = i\n",
    "            break\n",
    "\n",
    "    if header_row is None:\n",
    "        print(f\"Skipping {sheet_name}: No header with START and END found.\")\n",
    "        continue\n",
    "\n",
    "    # Load sheet with proper header\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row)\n",
    "    \n",
    "    # Drop rows with missing START or END\n",
    "    df = df.dropna(subset=[\"START\", \"END\"]).copy()\n",
    "\n",
    "    # Convert distance and duration fields\n",
    "    df[\"DISTANCE_M\"] = df[\"DISTANCE\"].apply(convert_distance)\n",
    "    df[\"DURATION_SEC\"] = df[\"DURATION\"].apply(convert_duration)\n",
    "    df[\"DURATION_IN_TRAFFIC_SEC\"] = df[\"DURATION_IN_TRAFFIC\"].apply(convert_duration)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Add time-based columns (if TIME column exists)\n",
    "    if \"TIME\" in df.columns:\n",
    "        df[\"TIME\"] = pd.to_datetime(df[\"TIME\"], errors=\"coerce\")\n",
    "        df[\"DATE\"] = df[\"TIME\"].dt.date\n",
    "        df[\"HOUR\"] = df[\"TIME\"].dt.hour\n",
    "        df[\"WEEKDAY\"] = df[\"TIME\"].dt.day_name()\n",
    "\n",
    "    cleaned_sheets[sheet_name] = df\n",
    "    print(f\"Cleaned {sheet_name}\")\n",
    "\n",
    "# Save cleaned data to a new Excel file\n",
    "output_path = \"cleaned_all_sheets_forward.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, cleaned_df in cleaned_sheets.items():\n",
    "        cleaned_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"\\n✅ Cleaning complete. Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"backward_combined.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "cleaned_sheets = {}\n",
    "\n",
    "# Conversion helpers\n",
    "def convert_distance(dist):\n",
    "    if isinstance(dist, str):\n",
    "        if \"km\" in dist:\n",
    "            num = float(dist.replace(\"km\", \"\").strip())\n",
    "            return int(num * 1000)\n",
    "        elif \"m\" in dist:\n",
    "            return int(dist.replace(\"m\", \"\").strip())\n",
    "    return pd.NA\n",
    "\n",
    "def convert_duration(dur):\n",
    "    if isinstance(dur, str):\n",
    "        minutes = re.findall(r\"(\\d+)\\s*min\", dur)\n",
    "        seconds = re.findall(r\"(\\d+)\\s*sec\", dur)\n",
    "        total = 0\n",
    "        if minutes:\n",
    "            total += int(minutes[0]) * 60\n",
    "        if seconds:\n",
    "            total += int(seconds[0])\n",
    "        return total\n",
    "    return pd.NA\n",
    "\n",
    "# Clean each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "    \n",
    "    # Detect correct header row\n",
    "    header_row = None\n",
    "    for i in range(10):\n",
    "        row = df_raw.iloc[i]\n",
    "        if \"START\" in row.values and \"END\" in row.values:\n",
    "            header_row = i\n",
    "            break\n",
    "\n",
    "    if header_row is None:\n",
    "        print(f\"Skipping {sheet_name}: No header with START and END found.\")\n",
    "        continue\n",
    "\n",
    "    # Load sheet with proper header\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row)\n",
    "    \n",
    "    # Drop rows with missing START or END\n",
    "    df = df.dropna(subset=[\"START\", \"END\"]).copy()\n",
    "\n",
    "    # Convert distance and duration fields\n",
    "    df[\"DISTANCE_M\"] = df[\"DISTANCE\"].apply(convert_distance)\n",
    "    df[\"DURATION_SEC\"] = df[\"DURATION\"].apply(convert_duration)\n",
    "    df[\"DURATION_IN_TRAFFIC_SEC\"] = df[\"DURATION_IN_TRAFFIC\"].apply(convert_duration)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Add time-based columns (if TIME column exists)\n",
    "    if \"TIME\" in df.columns:\n",
    "        df[\"TIME\"] = pd.to_datetime(df[\"TIME\"], errors=\"coerce\")\n",
    "        df[\"DATE\"] = df[\"TIME\"].dt.date\n",
    "        df[\"HOUR\"] = df[\"TIME\"].dt.hour\n",
    "        df[\"WEEKDAY\"] = df[\"TIME\"].dt.day_name()\n",
    "\n",
    "    cleaned_sheets[sheet_name] = df\n",
    "    print(f\"Cleaned {sheet_name}\")\n",
    "\n",
    "# Save cleaned data to a new Excel file\n",
    "output_path = \"cleaned_all_sheets_forward.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, cleaned_df in cleaned_sheets.items():\n",
    "        cleaned_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"\\n✅ Cleaning complete. Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dafcbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"copy_whole_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "cleaned_sheets = {}\n",
    "\n",
    "# Conversion helpers\n",
    "def convert_distance(dist):\n",
    "    if isinstance(dist, str):\n",
    "        if \"km\" in dist:\n",
    "            num = float(dist.replace(\"km\", \"\").strip())\n",
    "            return int(num * 1000)\n",
    "        elif \"m\" in dist:\n",
    "            return int(dist.replace(\"m\", \"\").strip())\n",
    "    return pd.NA\n",
    "\n",
    "def convert_duration(dur):\n",
    "    if isinstance(dur, str):\n",
    "        minutes = re.findall(r\"(\\d+)\\s*min\", dur)\n",
    "        seconds = re.findall(r\"(\\d+)\\s*sec\", dur)\n",
    "        total = 0\n",
    "        if minutes:\n",
    "            total += int(minutes[0]) * 60\n",
    "        if seconds:\n",
    "            total += int(seconds[0])\n",
    "        return total\n",
    "    return pd.NA\n",
    "\n",
    "# Clean each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "    \n",
    "    # Detect correct header row\n",
    "    header_row = None\n",
    "    for i in range(10):\n",
    "        row = df_raw.iloc[i]\n",
    "        if \"START\" in row.values and \"END\" in row.values:\n",
    "            header_row = i\n",
    "            break\n",
    "\n",
    "    if header_row is None:\n",
    "        print(f\"Skipping {sheet_name}: No header with START and END found.\")\n",
    "        continue\n",
    "\n",
    "    # Load sheet with proper header\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_row)\n",
    "    \n",
    "    # Drop rows with missing START or END\n",
    "    df = df.dropna(subset=[\"START\", \"END\"]).copy()\n",
    "\n",
    "    # Convert distance and duration fields\n",
    "    df[\"DISTANCE_M\"] = df[\"DISTANCE\"].apply(convert_distance)\n",
    "    df[\"DURATION_SEC\"] = df[\"DURATION\"].apply(convert_duration)\n",
    "    df[\"DURATION_IN_TRAFFIC_SEC\"] = df[\"DURATION_IN_TRAFFIC\"].apply(convert_duration)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Add time-based columns (if TIME column exists)\n",
    "    if \"TIME\" in df.columns:\n",
    "        df[\"TIME\"] = pd.to_datetime(df[\"TIME\"], errors=\"coerce\")\n",
    "        df[\"DATE\"] = df[\"TIME\"].dt.date\n",
    "        df[\"HOUR\"] = df[\"TIME\"].dt.hour\n",
    "        df[\"WEEKDAY\"] = df[\"TIME\"].dt.day_name()\n",
    "\n",
    "    cleaned_sheets[sheet_name] = df\n",
    "    print(f\"Cleaned {sheet_name}\")\n",
    "\n",
    "# Save cleaned data to a new Excel file\n",
    "output_path = \"cleaned_all_sheets_forward.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, cleaned_df in cleaned_sheets.items():\n",
    "        cleaned_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"\\n✅ Cleaning complete. Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"cleaned_all_sheets_forward - Copy.xlsx\"  # Update if your path is different\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Define the columns required for analysis\n",
    "required_columns = [\"START\", \"END\", \"DISTANCE_M\", \"DURATION_SEC\", \"DURATION_IN_TRAFFIC_SEC\"]\n",
    "\n",
    "# Check each sheet for readiness\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "    missing = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"❌ {sheet_name} is missing: {missing}\")\n",
    "    else:\n",
    "        print(f\"✅ {sheet_name} is ready for analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"cleaned_all_sheets_backward - Copy.xlsx\"  # Update if your path is different\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Define the columns required for analysis\n",
    "required_columns = [\"START\", \"END\", \"DISTANCE_M\", \"DURATION_SEC\", \"DURATION_IN_TRAFFIC_SEC\"]\n",
    "\n",
    "# Check each sheet for readiness\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "    missing = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"❌ {sheet_name} is missing: {missing}\")\n",
    "    else:\n",
    "        print(f\"✅ {sheet_name} is ready for analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b09454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set aesthetics for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"cleaned_all_sheets_forward - Copy.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Initialize empty DataFrame to combine all sheets\n",
    "all_data = []\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "    \n",
    "    # Keep only necessary columns and remove rows with missing/zero durations\n",
    "    df = df[[\"DISTANCE_M\", \"DURATION_SEC\", \"DURATION_IN_TRAFFIC_SEC\"]].dropna()\n",
    "    df = df[(df[\"DURATION_SEC\"] > 0) & (df[\"DURATION_IN_TRAFFIC_SEC\"] > 0)]\n",
    "    df[\"Sheet\"] = sheet_name  # Keep track of which sheet it came from\n",
    "    all_data.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Plotting Function\n",
    "def plot_distribution(column_name, bins=50):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=combined_df, x=column_name, bins=bins, kde=True, color='steelblue')\n",
    "    plt.title(f\"Distribution of {column_name}\", fontsize=16)\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot distributions\n",
    "plot_distribution(\"DISTANCE_M\")\n",
    "plot_distribution(\"DURATION_SEC\")\n",
    "plot_distribution(\"DURATION_IN_TRAFFIC_SEC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned Excel file\n",
    "file_path = \"cleaned_all_sheets_forward - Copy.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    # Check and drop rows with zero/negative values to avoid invalid calculations\n",
    "    df = df.dropna(subset=[\"DISTANCE_M\", \"DURATION_SEC\", \"DURATION_IN_TRAFFIC_SEC\"])\n",
    "    df = df[(df[\"DISTANCE_M\"] > 0) & (df[\"DURATION_SEC\"] > 0) & (df[\"DURATION_IN_TRAFFIC_SEC\"] > 0)]\n",
    "    \n",
    "    # Calculating traffic indices\n",
    "    df[\"TDI\"] = df[\"DURATION_IN_TRAFFIC_SEC\"] / df[\"DURATION_SEC\"]\n",
    "    df[\"Delay_Sec\"] = df[\"DURATION_IN_TRAFFIC_SEC\"] - df[\"DURATION_SEC\"]\n",
    "    df[\"Normalized_Delay\"] = df[\"Delay_Sec\"] / df[\"DISTANCE_M\"]\n",
    "    df[\"Speed_kmph\"] = (df[\"DISTANCE_M\"] / 1000) / (df[\"DURATION_IN_TRAFFIC_SEC\"] / 3600)\n",
    "\n",
    "    df[\"Sheet\"] = sheet_name\n",
    "    all_data.append(df)\n",
    "\n",
    "# Combine all sheets\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save to Excel\n",
    "combined_df.to_excel(\"indexed_traffic_data.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ All indices calculated and saved to 'indexed_traffic_data.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned Excel file\n",
    "file_path = \"cleaned_all_sheets_forward - Copy.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create Excel writer for saving sheet-wise indexed data\n",
    "with pd.ExcelWriter(\"indexed_sheetwise_forward.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        print(f\"Processing sheet: {sheet_name}\")\n",
    "        df = xls.parse(sheet_name)\n",
    "\n",
    "        # Drop invalid rows\n",
    "        df = df.dropna(subset=[\"DISTANCE_M\", \"DURATION_SEC\", \"DURATION_IN_TRAFFIC_SEC\"])\n",
    "        df = df[(df[\"DISTANCE_M\"] > 0) & (df[\"DURATION_SEC\"] > 0) & (df[\"DURATION_IN_TRAFFIC_SEC\"] > 0)]\n",
    "\n",
    "        # Compute indices\n",
    "        df[\"TDI\"] = df[\"DURATION_IN_TRAFFIC_SEC\"] / df[\"DURATION_SEC\"]\n",
    "        df[\"Delay_Sec\"] = df[\"DURATION_IN_TRAFFIC_SEC\"] - df[\"DURATION_SEC\"]\n",
    "        df[\"Normalized_Delay\"] = df[\"Delay_Sec\"] / df[\"DISTANCE_M\"]\n",
    "        df[\"Speed_kmph\"] = (df[\"DISTANCE_M\"] / 1000) / (df[\"DURATION_IN_TRAFFIC_SEC\"] / 3600)\n",
    "\n",
    "        # Save the modified DataFrame to the new Excel file\n",
    "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)  # Excel sheet names must be <= 31 chars\n",
    "\n",
    "print(\"✅ Done! Indexed data saved sheet-wise in 'indexed_sheetwise_forward.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772faa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlsxwriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd359d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned Excel file\n",
    "file_path = \"cleaned_all_sheets_forward - Copy.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create Excel writer for saving sheet-wise indexed data\n",
    "with pd.ExcelWriter(\"indexed_sheetwise_forward.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        print(f\"Processing sheet: {sheet_name}\")\n",
    "        df = xls.parse(sheet_name)\n",
    "\n",
    "        # Drop invalid rows\n",
    "        df = df.dropna(subset=[\"DISTANCE_M\", \"DURATION_SEC\", \"DURATION_IN_TRAFFIC_SEC\"])\n",
    "        df = df[(df[\"DISTANCE_M\"] > 0) & (df[\"DURATION_SEC\"] > 0) & (df[\"DURATION_IN_TRAFFIC_SEC\"] > 0)]\n",
    "\n",
    "        # Compute indices\n",
    "        df[\"TDI\"] = df[\"DURATION_IN_TRAFFIC_SEC\"] / df[\"DURATION_SEC\"]\n",
    "        df[\"Delay_Sec\"] = df[\"DURATION_IN_TRAFFIC_SEC\"] - df[\"DURATION_SEC\"]\n",
    "        df[\"Normalized_Delay\"] = df[\"Delay_Sec\"] / df[\"DISTANCE_M\"]\n",
    "        df[\"Speed_kmph\"] = (df[\"DISTANCE_M\"] / 1000) / (df[\"DURATION_IN_TRAFFIC_SEC\"] / 3600)\n",
    "\n",
    "        # Save the modified DataFrame to the new Excel file\n",
    "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)  # Excel sheet names must be <= 31 chars\n",
    "\n",
    "print(\"✅ Done! Indexed data saved sheet-wise in 'indexed_sheetwise_forward.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c83cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the indexed Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    # Ensure required columns are there\n",
    "    if \"HOUR\" in df.columns and \"TDI\" in df.columns:\n",
    "        grouped = df.groupby(\"HOUR\").agg({\n",
    "            \"TDI\": \"mean\",\n",
    "            \"Delay_Sec\": \"mean\",\n",
    "            \"Speed_kmph\": \"mean\"\n",
    "        }).reset_index()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.suptitle(f\"Hourly Traffic Impact – {sheet_name}\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "        # TDI\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.barplot(x=\"HOUR\", y=\"TDI\", data=grouped, palette=\"Blues_d\")\n",
    "        plt.title(\"Avg TDI by Hour\")\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Delay\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Delay_Sec\", data=grouped, palette=\"Oranges_d\")\n",
    "        plt.title(\"Avg Delay (Sec) by Hour\")\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Speed\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Speed_kmph\", data=grouped, palette=\"Greens_d\")\n",
    "        plt.title(\"Avg Speed (km/h) by Hour\")\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "sns.set(style=\"whitegrid\")  # Seaborn style for clean plots\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    if \"HOUR\" in df.columns and \"TDI\" in df.columns:\n",
    "        grouped = df.groupby(\"HOUR\").agg({\n",
    "            \"TDI\": \"mean\",\n",
    "            \"Delay_Sec\": \"mean\",\n",
    "            \"Speed_kmph\": \"mean\"\n",
    "        }).reset_index()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.suptitle(f\"Hourly Traffic Impact – {sheet_name}\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "        # TDI\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.barplot(x=\"HOUR\", y=\"TDI\", data=grouped, palette=\"Blues_d\")\n",
    "        plt.title(\"Avg TDI by Hour\")\n",
    "\n",
    "        # Delay\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Delay_Sec\", data=grouped, palette=\"Oranges_d\")\n",
    "        plt.title(\"Avg Delay (Sec) by Hour\")\n",
    "\n",
    "        # Speed\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Speed_kmph\", data=grouped, palette=\"Greens_d\")\n",
    "        plt.title(\"Avg Speed (km/h) by Hour\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()  # ← this ensures the plot appears\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efab5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this if using Jupyter\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "sns.set(style=\"whitegrid\")  # Seaborn style for clean plots\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    if \"HOUR\" in df.columns and \"TDI\" in df.columns:\n",
    "        grouped = df.groupby(\"HOUR\").agg({\n",
    "            \"TDI\": \"mean\",\n",
    "            \"Delay_Sec\": \"mean\",\n",
    "            \"Speed_kmph\": \"mean\"\n",
    "        }).reset_index()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.suptitle(f\"Hourly Traffic Impact – {sheet_name}\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "        # TDI\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.barplot(x=\"HOUR\", y=\"TDI\", data=grouped, palette=\"Blues_d\")\n",
    "        plt.title(\"Avg TDI by Hour\")\n",
    "\n",
    "        # Delay\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Delay_Sec\", data=grouped, palette=\"Oranges_d\")\n",
    "        plt.title(\"Avg Delay (Sec) by Hour\")\n",
    "\n",
    "        # Speed\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Speed_kmph\", data=grouped, palette=\"Greens_d\")\n",
    "        plt.title(\"Avg Speed (km/h) by Hour\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()  # ← this ensures the plot appears\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create output directory to save plots\n",
    "output_dir = \"hourly_traffic_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    if \"HOUR\" in df.columns and \"TDI\" in df.columns:\n",
    "        grouped = df.groupby(\"HOUR\").agg({\n",
    "            \"TDI\": \"mean\",\n",
    "            \"Delay_Sec\": \"mean\",\n",
    "            \"Speed_kmph\": \"mean\"\n",
    "        }).reset_index()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.suptitle(f\"Hourly Traffic Impact – {sheet_name}\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "        # TDI\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.barplot(x=\"HOUR\", y=\"TDI\", data=grouped, palette=\"Blues_d\")\n",
    "        plt.title(\"Avg TDI by Hour\")\n",
    "\n",
    "        # Delay\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Delay_Sec\", data=grouped, palette=\"Oranges_d\")\n",
    "        plt.title(\"Avg Delay (Sec) by Hour\")\n",
    "\n",
    "        # Speed\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.barplot(x=\"HOUR\", y=\"Speed_kmph\", data=grouped, palette=\"Greens_d\")\n",
    "        plt.title(\"Avg Speed (km/h) by Hour\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # Save the plot\n",
    "        file_name = f\"{sheet_name.replace('/', '_')}.png\"\n",
    "        plt.savefig(os.path.join(output_dir, file_name))\n",
    "        plt.close()\n",
    "\n",
    "print(f\"✅ All plots saved in the '{output_dir}' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe87b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Path to your indexed Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "\n",
    "# Create folder to save plots\n",
    "output_folder = \"hourly_traffic_plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Loop through each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    # Skip if HOUR or DURATION_IN_TRAFFIC_SEC missing\n",
    "    if 'HOUR' not in df.columns or 'DURATION_IN_TRAFFIC_SEC' not in df.columns:\n",
    "        print(f\"Skipping {sheet_name} (missing required columns)\")\n",
    "        continue\n",
    "\n",
    "    # Group by hour and calculate average duration in traffic\n",
    "    hourly_avg = df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    hourly_avg.plot(kind='bar', color='skyblue')\n",
    "    plt.title(f\"Avg. Traffic Duration by Hour\\n{sheet_name}\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Avg. Duration in Traffic (seconds)\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = os.path.join(output_folder, f\"{sheet_name}_hourly_traffic.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "for sheet in xls.sheet_names:\n",
    "    df = xls.parse(sheet, nrows=1)  # just read header\n",
    "    print(f\"{sheet}: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e889e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"hourly_traffic_plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load all sheet names\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "    \n",
    "    if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "        # Convert date-time column\n",
    "        df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "        df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "\n",
    "        # Group by hour\n",
    "        hourly_avg = df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        hourly_avg.plot(kind='bar', color='steelblue')\n",
    "        plt.title(f\"Average Traffic Duration by Hour\\n{sheet_name}\")\n",
    "        plt.xlabel(\"Hour of Day\")\n",
    "        plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save plot\n",
    "        plot_path = os.path.join(output_folder, f\"{sheet_name}_hourly_traffic.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot for {sheet_name}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Skipping {sheet_name} (missing DATE&TIME or DURATION_IN_TRAFFIC_SEC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984527df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"daily_traffic_plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load all sheet names\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "    \n",
    "    if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "        # Convert date-time column\n",
    "        df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "        df[\"DATE\"] = df[\"DATE&TIME\"].dt.date  # Extract date (day) from datetime\n",
    "\n",
    "        # Group by date\n",
    "        daily_avg = df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        daily_avg.plot(kind='bar', color='steelblue')\n",
    "        plt.title(f\"Average Traffic Duration by Day\\n{sheet_name}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save plot\n",
    "        plot_path = os.path.join(output_folder, f\"{sheet_name}_daily_traffic.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot for {sheet_name}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Skipping {sheet_name} (missing DATE&TIME or DURATION_IN_TRAFFIC_SEC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_avg.index, daily_avg.values, marker='o', linestyle='-', color='steelblue')\n",
    "plt.title(f\"Average Traffic Duration by Day\\n{sheet_name}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "\n",
    "# Format x-axis\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gcf().autofmt_xdate()  # Auto-rotate dates nicely\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plot_path = os.path.join(output_folder, f\"{sheet_name}_daily_traffic.png\")\n",
    "plt.savefig(plot_path)\n",
    "plt.close()\n",
    "print(f\"Saved plot for {sheet_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96667a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"daily_traffic_plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load all sheet names\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "    \n",
    "    if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "        # Convert date-time column\n",
    "        df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "        df[\"DATE\"] = df[\"DATE&TIME\"].dt.date  # Extract date\n",
    "\n",
    "        # Group by date\n",
    "        daily_avg = df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "        # Optional: Smooth with 7-day rolling average\n",
    "        # daily_avg = daily_avg.rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(daily_avg.index, daily_avg.values, marker='o', linestyle='-', color='steelblue')\n",
    "        plt.title(f\"Average Traffic Duration by Day\\n{sheet_name}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "\n",
    "        # Format x-axis\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Sanitize sheet name for saving\n",
    "        safe_sheet_name = \"\".join(c if c.isalnum() or c in \"._-\" else \"_\" for c in sheet_name)\n",
    "        plot_path = os.path.join(output_folder, f\"{safe_sheet_name}_daily_traffic.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot for {sheet_name}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping {sheet_name} (missing DATE&TIME or DURATION_IN_TRAFFIC_SEC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234fc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"combined_plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Store daily average delay per sheet\n",
    "daily_delays = {}\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = xls.parse(sheet_name)\n",
    "\n",
    "    if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "        df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "        df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "        daily_avg = df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "        daily_delays[sheet_name] = daily_avg\n",
    "    else:\n",
    "        print(f\"Skipping {sheet_name} (missing required columns)\")\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "combined_df = pd.DataFrame(daily_delays)\n",
    "combined_df.dropna(inplace=True)  # Ensure all stretches have data\n",
    "\n",
    "# Calculate the average delay across all stretches for each day\n",
    "combined_df[\"AVG_ALL_STRETCHES\"] = combined_df.mean(axis=1)\n",
    "\n",
    "# Find day with max and min\n",
    "max_day = combined_df[\"AVG_ALL_STRETCHES\"].idxmax()\n",
    "min_day = combined_df[\"AVG_ALL_STRETCHES\"].idxmin()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(combined_df.index, combined_df[\"AVG_ALL_STRETCHES\"], marker='o', linestyle='-', color='darkorange')\n",
    "plt.title(\"Average Delay Across All Stretches by Day\", fontsize=14)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Mark max and min\n",
    "plt.axvline(max_day, color='red', linestyle='--', label=f'Max: {max_day} ({combined_df[\"AVG_ALL_STRETCHES\"].max():.0f} sec)')\n",
    "plt.axvline(min_day, color='green', linestyle='--', label=f'Min: {min_day} ({combined_df[\"AVG_ALL_STRETCHES\"].min():.0f} sec)')\n",
    "\n",
    "# Format x-axis\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plot_path = os.path.join(output_folder, \"combined_daily_avg_delay.png\")\n",
    "plt.savefig(plot_path)\n",
    "plt.close()\n",
    "print(f\"✅ Plot saved at: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feae561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"  # Change path if needed\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Define sheet names for Flyover 1\n",
    "flyover_sheets = [\"Forward 1_Sheet4\", \"Forward 1_Sheet5\"]\n",
    "underpass_sheets = [\"Forward 1_Sheet6\", \"Forward 1_Sheet7\", \"Forward 2_Sheet1\"]\n",
    "\n",
    "# Create output directory\n",
    "output_folder = \"flyover_1_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Helper function to combine data from multiple sheets\n",
    "def get_combined_df(sheet_list):\n",
    "    dfs = []\n",
    "    for sheet in sheet_list:\n",
    "        if sheet in xls.sheet_names:\n",
    "            df = xls.parse(sheet)\n",
    "            if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "                df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "                df = df.dropna(subset=[\"DATE&TIME\"])\n",
    "                df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "                df[\"DAY\"] = df[\"DATE&TIME\"].dt.day_name()\n",
    "                dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Read and combine data\n",
    "flyover_df = get_combined_df(flyover_sheets)\n",
    "underpass_df = get_combined_df(underpass_sheets)\n",
    "\n",
    "# Hourly average comparison\n",
    "flyover_hourly = flyover_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "underpass_hourly = underpass_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(flyover_hourly.index, flyover_hourly.values, marker='o', label='Flyover (Above)')\n",
    "plt.plot(underpass_hourly.index, underpass_hourly.values, marker='o', label='Underpass (Below)')\n",
    "plt.title(\"Flyover vs Underpass - Hourly Avg Traffic Delay (Flyover 1)\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"hourly_comparison.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Day-wise average comparison\n",
    "flyover_daily = flyover_df.groupby(\"DAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "underpass_daily = underpass_df.groupby(\"DAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "# Ensure proper day order\n",
    "day_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "flyover_daily = flyover_daily.reindex(day_order)\n",
    "underpass_daily = underpass_daily.reindex(day_order)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(flyover_daily.index, flyover_daily.values, marker='o', label='Flyover (Above)')\n",
    "plt.plot(underpass_daily.index, underpass_daily.values, marker='o', label='Underpass (Below)')\n",
    "plt.title(\"Flyover vs Underpass - Day-wise Avg Traffic Delay (Flyover 1)\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"daywise_comparison.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime to just date (for daily average)\n",
    "flyover_df[\"DATE\"] = flyover_df[\"DATE&TIME\"].dt.date\n",
    "underpass_df[\"DATE\"] = underpass_df[\"DATE&TIME\"].dt.date\n",
    "\n",
    "# Daily average traffic delay\n",
    "flyover_datewise = flyover_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "underpass_datewise = underpass_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(flyover_datewise.index, flyover_datewise.values, marker='o', linestyle='-', label='Flyover (Above)')\n",
    "plt.plot(underpass_datewise.index, underpass_datewise.values, marker='o', linestyle='-', label='Underpass (Below)')\n",
    "plt.title(\"Flyover vs Underpass - Daily Avg Traffic Delay (Flyover 1)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"datewise_comparison.png\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387488f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Flyover 2 sheet mapping\n",
    "above_sheets = [\"Forward 2_Sheet5\", \"Forward 2_Sheet6\"]\n",
    "below_sheets = [\"Forward 2_Sheet7\", \"Forward 3_Sheet1\", \"Forward 3_Sheet2\"]\n",
    "\n",
    "# Path to the Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "\n",
    "# Create output folder\n",
    "output_folder = \"flyover_2_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "def extract_combined_data(sheet_names):\n",
    "    \"\"\"Extracts and combines data from specified sheets into a single DataFrame.\"\"\"\n",
    "    combined_df = pd.DataFrame()\n",
    "    for sheet in sheet_names:\n",
    "        if sheet not in xls.sheet_names:\n",
    "            print(f\"Warning: Sheet {sheet} not found in the file.\")\n",
    "            continue\n",
    "        df = xls.parse(sheet)\n",
    "        if \"DATE&TIME\" not in df.columns or \"DURATION_IN_TRAFFIC_SEC\" not in df.columns:\n",
    "            print(f\"Sheet {sheet} is missing required columns.\")\n",
    "            continue\n",
    "        df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"DATE&TIME\", \"DURATION_IN_TRAFFIC_SEC\"], inplace=True)\n",
    "        df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "        df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "        df[\"WEEKDAY\"] = df[\"DATE&TIME\"].dt.day_name()\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Extract data for above and below flyover paths\n",
    "above_df = extract_combined_data(above_sheets)\n",
    "below_df = extract_combined_data(below_sheets)\n",
    "\n",
    "# Plot 1: Weekday-wise Average Delay\n",
    "above_weekday = above_df.groupby(\"WEEKDAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "below_weekday = below_df.groupby(\"WEEKDAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "ordered_days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "above_weekday = above_weekday.reindex(ordered_days)\n",
    "below_weekday = below_weekday.reindex(ordered_days)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(above_weekday.index, above_weekday.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_weekday.index, below_weekday.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Weekday-wise Avg Traffic Delay - Flyover 2\")\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"weekday_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Hour-wise Average Delay\n",
    "above_hour = above_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "below_hour = below_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(above_hour.index, above_hour.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_hour.index, below_hour.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Hour-wise Avg Traffic Delay - Flyover 2\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.xticks(range(0, 24))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"hourly_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Day-wise Delay Trends (Actual Dates)\n",
    "above_daily = above_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "below_daily = below_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(above_daily.index, above_daily.values, label=\"Above Flyover\", marker='.')\n",
    "plt.plot(below_daily.index, below_daily.values, label=\"Below Flyover\", marker='.')\n",
    "plt.title(\"Daily Avg Delay Trend - Flyover 2\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_folder, \"daily_trend_comparison.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define file and output folder\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"flyover_3_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Sheets going above and below the flyover\n",
    "above_sheets = [\"Forward 3_Sheet4\", \"Forward 3_Sheet5\", \"Forward 3_Sheet6\"]\n",
    "below_sheets = [\"Forward 3_Sheet7\", \"Forward 4_Sheet1\", \"Forward 4_Sheet2\", \"Forward 4_Sheet3\"]\n",
    "\n",
    "# Load Excel\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "def get_daily_avg(sheet_names):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for sheet in sheet_names:\n",
    "        df = xls.parse(sheet)\n",
    "        if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "            df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "            df.dropna(subset=[\"DATE&TIME\"], inplace=True)\n",
    "            df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "            daily_avg = df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean().reset_index()\n",
    "            daily_avg.rename(columns={\"DURATION_IN_TRAFFIC_SEC\": sheet}, inplace=True)\n",
    "            if combined_df.empty:\n",
    "                combined_df = daily_avg\n",
    "            else:\n",
    "                combined_df = pd.merge(combined_df, daily_avg, on=\"DATE\", how=\"outer\")\n",
    "    combined_df.set_index(\"DATE\", inplace=True)\n",
    "    return combined_df\n",
    "\n",
    "# Get daily averages\n",
    "above_df = get_daily_avg(above_sheets)\n",
    "below_df = get_daily_avg(below_sheets)\n",
    "\n",
    "# Calculate mean across stretches\n",
    "above_mean = above_df.mean(axis=1)\n",
    "below_mean = below_df.mean(axis=1)\n",
    "\n",
    "# Plot hourly comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "above_mean.plot(label=\"Above Flyover\", linewidth=2)\n",
    "below_mean.plot(label=\"Below Flyover\", linewidth=2)\n",
    "plt.title(\"Flyover 3 - Daily Avg Delay (All Days)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover3_daily_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Day-wise comparison (e.g. Monday, Tuesday, ...)\n",
    "above_df_daywise = above_df.copy()\n",
    "below_df_daywise = below_df.copy()\n",
    "above_df_daywise[\"Day\"] = above_df_daywise.index.to_series().apply(lambda x: x.strftime(\"%A\"))\n",
    "below_df_daywise[\"Day\"] = below_df_daywise.index.to_series().apply(lambda x: x.strftime(\"%A\"))\n",
    "above_daywise = above_df_daywise.groupby(\"Day\").mean().mean(axis=1)\n",
    "below_daywise = below_df_daywise.groupby(\"Day\").mean().mean(axis=1)\n",
    "\n",
    "# Plot day-wise comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "above_daywise = above_daywise.loc[[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]]\n",
    "below_daywise = below_daywise.loc[[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]]\n",
    "plt.plot(above_daywise.index, above_daywise.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_daywise.index, below_daywise.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 3 - Avg Delay by Day of Week\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover3_daywise_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot full daily line chart\n",
    "plt.figure(figsize=(14, 6))\n",
    "for sheet in above_sheets:\n",
    "    if sheet in above_df.columns:\n",
    "        plt.plot(above_df.index, above_df[sheet], label=f\"Above - {sheet}\")\n",
    "for sheet in below_sheets:\n",
    "    if sheet in below_df.columns:\n",
    "        plt.plot(below_df.index, below_df[sheet], label=f\"Below - {sheet}\")\n",
    "plt.title(\"Flyover 3 - Daily Delay Trends (All Sheets)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover3_all_sheet_trends.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# File and sheet information\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"flyover_3_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define sheets for above and below\n",
    "above_sheets = [\"Forward 3_Sheet4\", \"Forward 3_Sheet5\", \"Forward 3_Sheet6\"]\n",
    "below_sheets = [\"Forward 3_Sheet7\", \"Forward 4_Sheet1\", \"Forward 4_Sheet2\", \"Forward 4_Sheet3\"]\n",
    "\n",
    "# Load Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "def load_and_process_sheets(sheet_list):\n",
    "    dfs = []\n",
    "    for sheet in sheet_list:\n",
    "        df = xls.parse(sheet)\n",
    "        if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "            df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "            df.dropna(subset=[\"DATE&TIME\"], inplace=True)\n",
    "            df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "            df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "# Process both above and below\n",
    "above_df = load_and_process_sheets(above_sheets)\n",
    "below_df = load_and_process_sheets(below_sheets)\n",
    "\n",
    "# Plot 1: Hour-wise comparison\n",
    "above_hourly = above_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "below_hourly = below_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(above_hourly.index, above_hourly.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_hourly.index, below_hourly.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 3 - Hourly Average Delay Comparison\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Average Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(range(24))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_3_hourly_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Day of Week Comparison\n",
    "above_df[\"DAY\"] = pd.to_datetime(above_df[\"DATE\"])\n",
    "below_df[\"DAY\"] = pd.to_datetime(below_df[\"DATE\"])\n",
    "above_df[\"WEEKDAY\"] = above_df[\"DAY\"].dt.day_name()\n",
    "below_df[\"WEEKDAY\"] = below_df[\"DAY\"].dt.day_name()\n",
    "\n",
    "above_weekday = above_df.groupby(\"WEEKDAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "below_weekday = below_df.groupby(\"WEEKDAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "# Ensure consistent weekday order\n",
    "weekday_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "above_weekday = above_weekday.reindex(weekday_order)\n",
    "below_weekday = below_weekday.reindex(weekday_order)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(above_weekday.index, above_weekday.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_weekday.index, below_weekday.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 3 - Day of Week Average Delay Comparison\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Average Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_3_weekday_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Daily Trend Line Plot\n",
    "above_daily = above_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "below_daily = below_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(above_daily.index, above_daily.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_daily.index, below_daily.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 3 - Daily Average Delay Trend\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Delay (sec)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_3_daily_trend.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flyover 4 Analysis Script\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# File and sheet details\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "sheets_above = [\"Forward 4_Sheet6\", \"Forward 4_Sheet7\"]\n",
    "sheets_below = [\"Forward 5_Sheet1\", \"Forward 5_Sheet2\", \"Forward 5_Sheet3\"]\n",
    "output_folder = \"flyover_4_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Helper function to load and concatenate sheets\n",
    "def load_and_prepare_sheets(sheet_names):\n",
    "    dfs = []\n",
    "    for name in sheet_names:\n",
    "        df = xls.parse(name)\n",
    "        if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "            df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors='coerce')\n",
    "            df = df.dropna(subset=[\"DATE&TIME\", \"DURATION_IN_TRAFFIC_SEC\"])\n",
    "            df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "            df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load data\n",
    "above_df = load_and_prepare_sheets(sheets_above)\n",
    "below_df = load_and_prepare_sheets(sheets_below)\n",
    "\n",
    "# 1. Hour-wise average comparison\n",
    "hourly_above = above_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "hourly_below = below_df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hourly_above.index, hourly_above.values, label='Above (Flyover)', marker='o')\n",
    "plt.plot(hourly_below.index, hourly_below.values, label='Below (Underpass)', marker='o')\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "plt.title(\"Flyover 4: Hour-wise Avg Traffic Delay\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_4_hourly_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 2. Day-wise average comparison\n",
    "daywise_above = above_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "daywise_below = below_df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daywise_above.index, daywise_above.values, label='Above (Flyover)', marker='o')\n",
    "plt.plot(daywise_below.index, daywise_below.values, label='Below (Underpass)', marker='o')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "plt.title(\"Flyover 4: Day-wise Avg Traffic Delay\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_4_daywise_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 3. Daily line plot for each (not grouped by weekday)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daywise_above.index, daywise_above.values, label='Above (Flyover)', marker='o')\n",
    "plt.plot(daywise_below.index, daywise_below.values, label='Below (Underpass)', marker='o')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Duration in Traffic (sec)\")\n",
    "plt.title(\"Flyover 4: Daily Avg Traffic Duration Line Plot\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_4_daily_line_plot.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved all Flyover 4 comparison plots in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# File and folder setup\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"flyover_4_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Sheets for flyover 4\n",
    "above_sheets = [\"Forward 4_Sheet6\", \"Forward 4_Sheet7\"]\n",
    "below_sheets = [\"Forward 5_Sheet1\", \"Forward 5_Sheet2\", \"Forward 5_Sheet3\"]\n",
    "\n",
    "# Load Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Helper function to aggregate all required data from sheets\n",
    "def get_combined_df(sheet_names):\n",
    "    df_list = []\n",
    "    for sheet in sheet_names:\n",
    "        df = xls.parse(sheet)\n",
    "        if \"DATE&TIME\" in df.columns and \"DURATION_IN_TRAFFIC_SEC\" in df.columns:\n",
    "            df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors='coerce')\n",
    "            df = df.dropna(subset=[\"DATE&TIME\", \"DURATION_IN_TRAFFIC_SEC\"])\n",
    "            df_list.append(df[[\"DATE&TIME\", \"DURATION_IN_TRAFFIC_SEC\"]])\n",
    "        else:\n",
    "            print(f\"Skipping {sheet} due to missing columns.\")\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "# Get data\n",
    "above_df = get_combined_df(above_sheets)\n",
    "below_df = get_combined_df(below_sheets)\n",
    "\n",
    "# HOURLY AVERAGE PLOT\n",
    "def plot_hourly(df, label):\n",
    "    df[\"HOUR\"] = df[\"DATE&TIME\"].dt.hour\n",
    "    return df.groupby(\"HOUR\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "above_hourly = plot_hourly(above_df, \"Above\")\n",
    "below_hourly = plot_hourly(below_df, \"Below\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(above_hourly.index, above_hourly.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_hourly.index, below_hourly.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 4 - Hourly Avg Traffic Delay (sec)\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_4_hourly_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# DAILY AVERAGE PLOT\n",
    "def plot_daily(df):\n",
    "    df[\"DATE\"] = df[\"DATE&TIME\"].dt.date\n",
    "    return df.groupby(\"DATE\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "above_daily = plot_daily(above_df)\n",
    "below_daily = plot_daily(below_df)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(above_daily.index, above_daily.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_daily.index, below_daily.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 4 - Day-wise Avg Traffic Delay (sec)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_4_daily_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# WEEKDAY-WISE AVERAGE PLOT\n",
    "def plot_weekday(df):\n",
    "    df[\"WEEKDAY\"] = df[\"DATE&TIME\"].dt.day_name()\n",
    "    return df.groupby(\"WEEKDAY\")[\"DURATION_IN_TRAFFIC_SEC\"].mean()\n",
    "\n",
    "# Define custom weekday order\n",
    "weekday_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "above_weekday = plot_weekday(above_df).reindex(weekday_order)\n",
    "below_weekday = plot_weekday(below_df).reindex(weekday_order)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(above_weekday.index, above_weekday.values, label=\"Above Flyover\", marker='o')\n",
    "plt.plot(below_weekday.index, below_weekday.values, label=\"Below Flyover\", marker='o')\n",
    "plt.title(\"Flyover 4 - Weekday-wise Avg Traffic Delay (sec)\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Avg Delay (sec)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"flyover_4_weekday_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"All Flyover 4 plots generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Setup ===\n",
    "file_path = \"forward_combined_cleaned.xlsx\"  # Replace with your actual file\n",
    "output_folder = \"weekday_weekend_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read all sheets\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# === Load and process each sheet ===\n",
    "for sheet in sheet_names:\n",
    "    df = xls.parse(sheet)\n",
    "    \n",
    "    # Normalize column names\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "    \n",
    "    # Check for required columns\n",
    "    if 'date' not in df.columns or 'traffic delay' not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df.dropna(subset=['date'], inplace=True)\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'] >= 5\n",
    "    df['stretch'] = sheet\n",
    "    all_data.append(df[['date', 'traffic delay', 'is_weekend', 'stretch']])\n",
    "\n",
    "# === Combine all data ===\n",
    "combined = pd.concat(all_data)\n",
    "\n",
    "# === Grouped Statistics ===\n",
    "grouped = combined.groupby('is_weekend')['traffic delay'].agg(['mean', 'std']).reset_index()\n",
    "grouped['day_type'] = grouped['is_weekend'].map({False: 'Weekdays (Mon-Fri)', True: 'Weekends (Sat-Sun)'})\n",
    "\n",
    "# === Bar Plot with Std Dev ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(grouped['day_type'], grouped['mean'], yerr=grouped['std'], capsize=10, color=['skyblue', 'salmon'])\n",
    "plt.ylabel('Average Traffic Delay (seconds)')\n",
    "plt.title('Traffic Delay: Weekdays vs Weekends (with Variance)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save bar plot\n",
    "bar_path = os.path.join(output_folder, 'weekday_weekend_bar_variance.png')\n",
    "plt.savefig(bar_path)\n",
    "plt.close()\n",
    "print(f\"Bar chart saved to {bar_path}\")\n",
    "\n",
    "# === Box Plot for distribution ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "combined['day_type'] = combined['is_weekend'].map({False: 'Weekdays (Mon-Fri)', True: 'Weekends (Sat-Sun)'})\n",
    "combined.boxplot(column='traffic delay', by='day_type', grid=False)\n",
    "plt.title('Traffic Delay Distribution: Weekdays vs Weekends')\n",
    "plt.suptitle('')\n",
    "plt.ylabel('Traffic Delay (seconds)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save boxplot\n",
    "box_path = os.path.join(output_folder, 'weekday_weekend_boxplot.png')\n",
    "plt.savefig(box_path)\n",
    "plt.close()\n",
    "print(f\"Box plot saved to {box_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc50c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Setup ===\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"  # Your actual file name\n",
    "output_folder = \"weekday_weekend_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read all sheets\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# === Load and process each sheet ===\n",
    "for sheet in sheet_names:\n",
    "    df = xls.parse(sheet)\n",
    "    \n",
    "    # Normalize column names\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "    \n",
    "    # Check for required columns\n",
    "    if 'date' not in df.columns or 'traffic delay' not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df.dropna(subset=['date'], inplace=True)\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_]()_]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Setup ===\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"  # Your actual file name\n",
    "output_folder = \"weekday_weekend_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read all sheets\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# === Load and process each sheet ===\n",
    "for sheet in sheet_names:\n",
    "    df = xls.parse(sheet)\n",
    "    \n",
    "    # Normalize column names\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "    \n",
    "    # Check for required columns\n",
    "    if 'date' not in df.columns or 'traffic delay' not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df.dropna(subset=['date'], inplace=True)\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'] >= 5\n",
    "    df['stretch'] = sheet\n",
    "    all_data.append(df[['date', 'traffic delay', 'is_weekend', 'stretch']])\n",
    "\n",
    "# === Combine all data ===\n",
    "combined = pd.concat(all_data)\n",
    "\n",
    "# === Grouped Statistics ===\n",
    "grouped = combined.groupby('is_weekend')['traffic delay'].agg(['mean', 'std']).reset_index()\n",
    "grouped['day_type'] = grouped['is_weekend'].map({False: 'Weekdays (Mon-Fri)', True: 'Weekends (Sat-Sun)'})\n",
    "\n",
    "# === Bar Plot with Std Dev ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(grouped['day_type'], grouped['mean'], yerr=grouped['std'], capsize=10, color=['skyblue', 'salmon'])\n",
    "plt.ylabel('Average Traffic Delay (seconds)')\n",
    "plt.title('Traffic Delay: Weekdays vs Weekends (with Variance)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save bar plot\n",
    "bar_path = os.path.join(output_folder, 'weekday_weekend_bar_variance.png')\n",
    "plt.savefig(bar_path)\n",
    "plt.close()\n",
    "print(f\"Bar chart saved to {bar_path}\")\n",
    "\n",
    "# === Box Plot for distribution ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "combined['day_type'] = combined['is_weekend'].map({False: 'Weekdays (Mon-Fri)', True: 'Weekends (Sat-Sun)'})\n",
    "combined.boxplot(column='traffic delay', by='day_type', grid=False)\n",
    "plt.title('Traffic Delay Distribution: Weekdays vs Weekends')\n",
    "plt.suptitle('')\n",
    "plt.ylabel('Traffic Delay (seconds)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save boxplot\n",
    "box_path = os.path.join(output_folder, 'weekday_weekend_boxplot.png')\n",
    "plt.savefig(box_path)\n",
    "plt.close()\n",
    "print(f\"Box plot saved to {box_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Combine all data from sheets\n",
    "all_data = []\n",
    "for sheet in xls.sheet_names:\n",
    "    df = xls.parse(sheet)\n",
    "    df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"])\n",
    "    df[\"Weekday\"] = df[\"DATE&TIME\"].dt.day_name()\n",
    "    df[\"Is_Weekend\"] = df[\"Weekday\"].isin([\"Saturday\", \"Sunday\"])\n",
    "    all_data.append(df)\n",
    "\n",
    "# Combine into single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Group by Is_Weekend and compute average delay\n",
    "avg_delay = combined_df.groupby(\"Is_Weekend\")[\"Delay_Sec\"].mean().reset_index()\n",
    "avg_delay[\"Day_Type\"] = avg_delay[\"Is_Weekend\"].map({True: \"Weekend\", False: \"Weekday\"})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(avg_delay[\"Day_Type\"], avg_delay[\"Delay_Sec\"], color=[\"skyblue\", \"salmon\"])\n",
    "plt.title(\"Average Delay: Weekday vs Weekend\")\n",
    "plt.ylabel(\"Average Delay (seconds)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"weekday_vs_weekend_delay.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f93183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "output_folder = \"weekend_weekday_analysis\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read all sheets\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for sheet in sheet_names:\n",
    "    try:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet, usecols=[\"DATE&TIME\", \"Delay_Sec\"])\n",
    "        df.dropna(subset=[\"DATE&TIME\", \"Delay_Sec\"], inplace=True)\n",
    "        df[\"DATE&TIME\"] = pd.to_datetime(df[\"DATE&TIME\"], errors=\"coerce\")\n",
    "        df[\"Sheet\"] = sheet\n",
    "        df[\"Date\"] = df[\"DATE&TIME\"].dt.date\n",
    "        df[\"Hour\"] = df[\"DATE&TIME\"].dt.hour\n",
    "        df[\"Weekday_Name\"] = df[\"DATE&TIME\"].dt.day_name()\n",
    "        df[\"Is_Weekend\"] = df[\"Weekday_Name\"].isin([\"Saturday\", \"Sunday\"])\n",
    "        all_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {sheet}: {e}\")\n",
    "\n",
    "# Combine all data\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Plot 1: Average Delay - Weekday vs Weekend\n",
    "avg_delay = combined_df.groupby(\"Is_Weekend\")[\"Delay_Sec\"].mean().reset_index()\n",
    "avg_delay[\"Type\"] = avg_delay[\"Is_Weekend\"].map({True: \"Weekend\", False: \"Weekday\"})\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.barplot(x=\"Type\", y=\"Delay_Sec\", data=avg_delay, palette=\"Set2\")\n",
    "plt.title(\"Average Delay: Weekday vs Weekend\")\n",
    "plt.ylabel(\"Average Delay (sec)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"avg_delay_weekday_vs_weekend.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Boxplot by Weekday\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"Weekday_Name\", y=\"Delay_Sec\", data=combined_df,\n",
    "            order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    "            palette=\"Set3\")\n",
    "plt.title(\"Delay Distribution by Weekday\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"boxplot_delay_by_weekday.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Standard Deviation by Weekday\n",
    "std_dev = combined_df.groupby(\"Weekday_Name\")[\"Delay_Sec\"].std().reindex(\n",
    "    [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"Weekday_Name\", y=\"Delay_Sec\", data=std_dev, palette=\"coolwarm\")\n",
    "plt.title(\"Standard Deviation of Delay by Weekday\")\n",
    "plt.ylabel(\"Standard Deviation (sec)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"std_deviation_by_weekday.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot 4: Heatmap - Average Delay by Weekday & Hour\n",
    "heatmap_data = combined_df.groupby([\"Weekday_Name\", \"Hour\"])[\"Delay_Sec\"].mean().reset_index()\n",
    "heatmap_pivot = heatmap_data.pivot(index=\"Weekday_Name\", columns=\"Hour\", values=\"Delay_Sec\").reindex([\n",
    "    \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(heatmap_pivot, cmap=\"YlOrRd\", annot=True, fmt=\".0f\", linewidths=0.5)\n",
    "plt.title(\"Average Delay (sec) by Weekday and Hour\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Weekday\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"heatmap_delay_by_weekday_hour.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load Excel\n",
    "file_path = 'indexed_sheetwise_forward.xlsx'\n",
    "xls = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Time bins\n",
    "time_bins = [0, 3, 6, 9, 12, 15, 18, 21, 24]\n",
    "bin_labels = ['12am-3am', '3am-6am', '6am-9am', '9am-12pm', '12pm-3pm', '3pm-6pm', '6pm-9pm', '9pm-12am']\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'traffic_plots'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Summary table\n",
    "summary = pd.DataFrame()\n",
    "\n",
    "# Process each sheet\n",
    "for stretch_name, df in xls.items():\n",
    "    if 'Time' not in df.columns or 'Speed_kmph' not in df.columns:\n",
    "        continue\n",
    "\n",
    "    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "    df = df.dropna(subset=['Time', 'Speed_kmph'])\n",
    "    df['Hour'] = df['Time'].dt.hour\n",
    "    df['Time_Bin'] = pd.cut(df['Hour'], bins=time_bins, labels=bin_labels, right=False, include_lowest=True)\n",
    "\n",
    "    avg_speeds = df.groupby('Time_Bin')['Speed_kmph'].mean().reindex(bin_labels)\n",
    "    avg_speeds.name = stretch_name\n",
    "    summary = pd.concat([summary, avg_speeds], axis=1)\n",
    "\n",
    "# Final table\n",
    "summary = summary.transpose()\n",
    "summary.index.name = 'Stretch'\n",
    "summary = summary.astype(float)\n",
    "\n",
    "# Save summary\n",
    "summary.to_csv(os.path.join(output_dir, 'avg_speed_by_stretch_and_time.csv'))\n",
    "\n",
    "# === 1. Heatmap ===\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(summary, annot=True, cmap='YlOrRd')\n",
    "plt.title('Average Speed (km/h) by Stretch and Time Bin')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Road Stretch')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'heatmap_avg_speed.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 2. Line Plot ===\n",
    "plt.figure(figsize=(14, 8))\n",
    "for stretch in summary.index:\n",
    "    plt.plot(summary.columns, summary.loc[stretch], label=stretch, alpha=0.5)\n",
    "plt.title('Speed Variation Across Time Bins')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Speed (km/h)')\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'lineplot_speed_variation.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 3. Bar Chart ===\n",
    "avg_by_stretch = summary.mean(axis=1).sort_values()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=avg_by_stretch.values, y=avg_by_stretch.index, palette='coolwarm')\n",
    "plt.title('Overall Average Speed by Stretch')\n",
    "plt.xlabel('Average Speed (km/h)')\n",
    "plt.ylabel('Stretch')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'barchart_avg_speed.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 4. Box Plot ===\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(data=summary, orient='h', palette='Set3')\n",
    "plt.title('Speed Distribution per Time Bin Across Stretches')\n",
    "plt.xlabel('Average Speed (km/h)')\n",
    "plt.ylabel('Time Bin')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'boxplot_speed_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 5. Identify Problematic Stretches ===\n",
    "low_speed_flags = (summary < 20).sum(axis=1)\n",
    "slow_stretches = low_speed_flags[low_speed_flags >= 4]\n",
    "slow_stretches.to_csv(os.path.join(output_dir, \"problematic_stretches.csv\"), header=[\"LowSpeed_Bin_Count\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"indexed_sheetwise_forward.xlsx\"\n",
    "xls = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Prepare output directory\n",
    "output_dir = \"traffic_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define time bins\n",
    "time_bins = [0, 3, 6, 9, 12, 15, 18, 21, 24]\n",
    "bin_labels = ['12am-3am', '3am-6am', '6am-9am', '9am-12pm',\n",
    "              '12pm-3pm', '3pm-6pm', '6pm-9pm', '9pm-12am']\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "skipped_sheets = []\n",
    "\n",
    "# Process each sheet\n",
    "for stretch_name, df in xls.items():\n",
    "    if 'DATE&TIME' not in df.columns or 'Speed_kmph' not in df.columns:\n",
    "        skipped_sheets.append(stretch_name)\n",
    "        continue\n",
    "\n",
    "    df = df.dropna(subset=['DATE&TIME', 'Speed_kmph'])\n",
    "    df['DATE&TIME'] = pd.to_datetime(df['DATE&TIME'], errors='coerce')\n",
    "    df = df.dropna(subset=['DATE&TIME'])\n",
    "    df['Hour'] = df['DATE&TIME'].dt.hour\n",
    "    df['Time_Bin'] = pd.cut(df['Hour'], bins=time_bins, labels=bin_labels, right=False, include_lowest=True)\n",
    "\n",
    "    avg_speeds = df.groupby('Time_Bin')['Speed_kmph'].mean().reindex(bin_labels)\n",
    "    avg_speeds.name = stretch_name\n",
    "    summary = pd.concat([summary, avg_speeds], axis=1)\n",
    "\n",
    "# Final formatting\n",
    "summary = summary.transpose()\n",
    "summary.index.name = 'Stretch'\n",
    "summary = summary.astype(float)\n",
    "summary.dropna(how='all', inplace=True)\n",
    "summary.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Save summary table\n",
    "summary.to_csv(os.path.join(output_dir, 'avg_speed_by_stretch_and_time.csv'))\n",
    "\n",
    "# === 1. Heatmap ===\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(summary, annot=True, cmap='YlOrRd')\n",
    "plt.title('Average Speed (km/h) by Stretch and Time Bin')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Road Stretch')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'heatmap_avg_speed.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 2. Line Plot ===\n",
    "plt.figure(figsize=(14, 8))\n",
    "for stretch in summary.index:\n",
    "    plt.plot(summary.columns, summary.loc[stretch], label=stretch, alpha=0.5)\n",
    "plt.title('Speed Variation Across Time Bins')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Speed (km/h)')\n",
    "plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'lineplot_speed_variation.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 3. Bar Chart: Overall Avg Speed by Stretch ===\n",
    "avg_by_stretch = summary.mean(axis=1).sort_values()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=avg_by_stretch.values, y=avg_by_stretch.index, palette='coolwarm')\n",
    "plt.title('Overall Average Speed by Stretch')\n",
    "plt.xlabel('Average Speed (km/h)')\n",
    "plt.ylabel('Stretch')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'barchart_avg_speed.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 4. Box Plot: Speed Distribution by Time Bin ===\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(data=summary, orient='h', palette='Set3')\n",
    "plt.title('Speed Distribution per Time Bin Across Stretches')\n",
    "plt.xlabel('Average Speed (km/h)')\n",
    "plt.ylabel('Time Bin')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'boxplot_speed_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === 5. Problematic Stretches ===\n",
    "low_speed_flags = (summary < 20).sum(axis=1)\n",
    "slow_stretches = low_speed_flags[low_speed_flags >= 4]\n",
    "slow_stretches.to_csv(os.path.join(output_dir, \"problematic_stretches.csv\"), header=[\"LowSpeed_Bin_Count\"])\n",
    "\n",
    "# Optional: Print skipped sheets\n",
    "print(\"Skipped sheets due to missing columns:\", skipped_sheets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_excel(\"your_file.xlsx\", index_col=0)  # Assuming first column is Time Bin\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"stretch_speed_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Plot for each stretch\n",
    "for stretch in df.columns:\n",
    "    avg_speeds = df[stretch]\n",
    "    mean_speed = avg_speeds.mean()\n",
    "    std_speed = avg_speeds.std()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df.index, avg_speeds, marker='o', label=\"Avg Speed\", color='blue')\n",
    "    plt.axhline(mean_speed, color='green', linestyle='--', label=f\"Mean = {mean_speed:.2f}\")\n",
    "    plt.axhline(mean_speed + std_speed, color='red', linestyle=':', label=f\"+1 Std Dev = {mean_speed + std_speed:.2f}\")\n",
    "    plt.axhline(mean_speed - std_speed, color='red', linestyle=':', label=f\"-1 Std Dev = {mean_speed - std_speed:.2f}\")\n",
    "\n",
    "    plt.title(f\"Speed Trend for {stretch}\")\n",
    "    plt.xlabel(\"Time Bin\")\n",
    "    plt.ylabel(\"Average Speed (km/h)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f\"{output_dir}/{stretch}_speed_trend.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(f\"All plots saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_excel(\"indexed_sheetwise_forward.xlsx\", index_col=0) # Assuming first column is Time Bin\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"stretch_speed_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Plot for each stretch\n",
    "for stretch in df.columns:\n",
    "    avg_speeds = df[stretch]\n",
    "    mean_speed = avg_speeds.mean()\n",
    "    std_speed = avg_speeds.std()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df.index, avg_speeds, marker='o', label=\"Avg Speed\", color='blue')\n",
    "    plt.axhline(mean_speed, color='green', linestyle='--', label=f\"Mean = {mean_speed:.2f}\")\n",
    "    plt.axhline(mean_speed + std_speed, color='red', linestyle=':', label=f\"+1 Std Dev = {mean_speed + std_speed:.2f}\")\n",
    "    plt.axhline(mean_speed - std_speed, color='red', linestyle=':', label=f\"-1 Std Dev = {mean_speed - std_speed:.2f}\")\n",
    "\n",
    "    plt.title(f\"Speed Trend for {stretch}\")\n",
    "    plt.xlabel(\"Time Bin\")\n",
    "    plt.ylabel(\"Average Speed (km/h)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f\"{output_dir}/{stretch}_speed_trend.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(f\"All plots saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ae6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9003263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Individual Stretch Plots with Mean and Std Dev ===\n",
    "individual_plot_dir = os.path.join(output_dir, \"individual_stretch_plots\")\n",
    "os.makedirs(individual_plot_dir, exist_ok=True)\n",
    "\n",
    "for stretch in summary.index:\n",
    "    speeds = summary.loc[stretch]\n",
    "    mean_speed = speeds.mean()\n",
    "    std_speed = speeds.std()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=speeds.index, y=speeds.values, marker='o', label='Avg Speed')\n",
    "    \n",
    "    # Plot mean line\n",
    "    plt.axhline(mean_speed, color='green', linestyle='--', label=f'Mean ({mean_speed:.2f} km/h)')\n",
    "    \n",
    "    # Plot shaded std dev area\n",
    "    plt.fill_between(speeds.index,\n",
    "                     mean_speed - std_speed,\n",
    "                     mean_speed + std_speed,\n",
    "                     color='green',\n",
    "                     alpha=0.2,\n",
    "                     label=f'±1 Std Dev ({std_speed:.2f})')\n",
    "\n",
    "    plt.title(f'Average Speed Trend for {stretch}')\n",
    "    plt.xlabel('Time Bin')\n",
    "    plt.ylabel('Average Speed (km/h)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(individual_plot_dir, f\"{stretch}_speed_plot.png\"), dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b86cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
